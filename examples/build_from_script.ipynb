{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model from Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example a simple **SFINCS** compound flood model will be made, using the underlying Python functions of **HydroMT-SFINCS** to build a model.\n",
    "\n",
    "The model is situated in **Northern Italy**, where a small selection of topography and bathymetry data has already been made available for you to try the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from hydromt_sfincs import SfincsModel\n",
    "from hydromt_sfincs import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to build a SFINCS model containing elevation data and spatially varying roughness (together processed into subgrid tables), spatially varying infiltration and a local floodwall. In addition, multiple forcing conditions are set-up, and this is all done using Python scripting.\n",
    "\n",
    "In case you want to adjust this example to build a SFINCS model anywhere else in the world, you will have to add your own datasets to HydroMT's data catalog. For more info on that, check-out:\n",
    "\n",
    "- [Prepare data catalog](https://deltares.github.io/hydromt/latest/user_guide/data_prepare_cat.html)\n",
    "\n",
    "- [Example: Prepare data catalog](https://deltares.github.io/hydromt/latest/_examples/prep_data_catalog.html)\n",
    "\n",
    "- [Example: Datasources](example_datasources.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps followed in this notebook to build your SFINCS model:**\n",
    "<ol> \n",
    "<li> Open SfincsModel class, set data library and output folder </li>\n",
    "<li> Specify characteristics of the wanted grid </li>\n",
    "<li> Load in wanted elevation datasets </li>\n",
    "<li> Make mask of active and inactive cells </li>\n",
    "<li> Update mask with water level and outflow boundary cells</li>\n",
    "<li> Add spatially varying roughness data</li>\n",
    "<li> Make subgrid derived tables</li>\n",
    "<li> Add spatially varying infiltration data</li>\n",
    "<li> Add water level time-series as forcing</li>\n",
    "<li> Add an upstream discharge time-series as forcing</li>\n",
    "<li> Add spatially varying rainfall data</li>\n",
    "<li> Add weirfile</li>\n",
    "<li> Add observation points</li>\n",
    "<li> Add observation lines</li>\n",
    "<li> Show model</li>\n",
    "<li> Save all files</li>\n",
    "</ol> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialize SfincsModel class, set data library and output folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SfincsModel Python class with the artifact data catalog which contains publically available data for North Italy\n",
    "# we overwrite (mode='w+') the existing model in the root directory if it exists\n",
    "sf = SfincsModel(data_libs=[\"artifact_data\"], root=\"tmp_sfincs_compound\", mode=\"w+\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Specify characteristics of the wanted grid and generate grid:\n",
    "\n",
    "For more info about how to define a grid, [click here](https://sfincs.readthedocs.io/en/latest/input.html#grid-characteristics). \n",
    "\n",
    "*Hint: if you only have a bounding box or geometry, you can also use `SfincsModel.setup_grid_from_region`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an input dictionary with the grid settings x0,y0,dx,dy,nmax,mmax,rotation and epsg code.\n",
    "# create SFINCS model with regular grid and characteristics of the input dictionary:\n",
    "sf.setup_grid(\n",
    "    x0=318650,\n",
    "    y0=5040000,\n",
    "    dx=50.0,\n",
    "    dy=50.0,\n",
    "    nmax=107,\n",
    "    mmax=250,\n",
    "    rotation=27,\n",
    "    epsg=32633,\n",
    ")\n",
    "\n",
    "# Alternatively, we can also use a shape/geojson file to define the grid:\n",
    "# sf.setup_grid_from_region(\n",
    "#     region = {'geom': 'data/region.geojson'},\n",
    "#     res= 50,\n",
    "#     rotated=True,\n",
    "#     crs=32633\n",
    "# )\n",
    "\n",
    "# the input file is automatically updated. Uncomment to displayed below:\n",
    "print(sf.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the model grid outline\n",
    "# sf.region.boundary.plot(figsize=(6,6))\n",
    "_ = sf.plot_basemap(plot_region=True, bmap=\"sat\", zoomlevel=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load in wanted elevation datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example we want to combine 2 elevation datasets, merit_hydro as elevation and gebco as bathymetry, in that order.\n",
    "\n",
    "# NOTE: from the 1st dataset (merit_hydro) only elevation above (\"zmin\":0.001) meters is used;\n",
    "# the 2nd elevation dataset (gebco) is used where the 1st dataset returned nodata values\n",
    "datasets_dep = [{\"elevtn\": \"merit_hydro\", \"zmin\": 0.001}, {\"elevtn\": \"gebco\"}]\n",
    "\n",
    "# Add depth information to modelgrid based on these chosen datasets\n",
    "dep = sf.setup_dep(datasets_dep=datasets_dep)\n",
    "\n",
    "# Make a plot of the merged topobathy, here colour limits are set between an elevation of -5 to 5 meters\n",
    "_ = sf.plot_basemap(variable=\"dep\", bmap=\"sat\", zoomlevel=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make mask of active and inactive cells:\n",
    "\n",
    "Here we generate the mask of active (msk=1) and inactive cells (msk=0), determining what cells on your grid should be used. \n",
    "For more info about the msk-file, [click here](https://sfincs.readthedocs.io/en/latest/input.html#mask-file). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing how to choose you active cells can be based on multiple criteria, here we only specify a minimum elevation of -5 meters\n",
    "sf.setup_mask_active(zmin=-5, reset_mask=True)\n",
    "\n",
    "# Make a plot of the mask file\n",
    "_ = sf.plot_basemap(variable=\"msk\", plot_bounds=True, bmap=\"sat\", zoomlevel=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "- The given output of HydroMT says \"3 gaps outside valid elevation range < 10 km2\". \n",
    "HydroMT does some smart filtering that if small groups of inactive cells are found, surrounded by active cells, these are still included as active, in this case 3 gaps.\n",
    "You can control the size of these gaps to filter by adding `fill_area = 10` in `setup_mask_active()`.\n",
    "- A similar argument exists to neglect a group of active cells surrounded by inactive cells: `drop_area`\n",
    "- `reset_mask=True` means that every time you start with an ampy mask while defining your msk cells, if `reset_bounds=False` (default) you continue on the prevous time you ran that function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Update mask with water level and outflow boundary cells - including use of polygons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a shapefile clicked by user:\n",
    "file_name = \"data//compound_example_outflow_boundary_polygon.geojson\"\n",
    "gdf_include = sf.data_catalog.get_geodataframe(file_name)\n",
    "\n",
    "# Example of the same, but how to load an existing ascii .pol file with x&y-coordinates, e.g. coming out of Delft Dashboard, here assumed to be in the CRS of the SFINCS model:\n",
    "# file_name = \"XX.pol\"\n",
    "# gdf_include = utils.polygon2gdf(feats=utils.read_geoms(fn=file_name), crs=sf.crs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SFINCS you can specify cells where you want to force offshore water levels (msk=2), or outflow boundaries (msk=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we add water level cells along the coastal boundary, for cells up to an elevation of -5 meters\n",
    "sf.setup_mask_bounds(btype=\"waterlevel\", zmax=-5, reset_bounds=True)\n",
    "\n",
    "# Here we add outflow cells, only where clicked in shapefile along part of the lateral boundaries\n",
    "sf.setup_mask_bounds(btype=\"outflow\", include_mask=gdf_include, reset_bounds=True)\n",
    "\n",
    "# Make a plot of the mask file\n",
    "fig, ax = sf.plot_basemap(variable=\"msk\", plot_bounds=True, bmap=\"sat\", zoomlevel=12)\n",
    "gdf_include.to_crs(sf.crs).boundary.plot(\n",
    "    ax=ax, color=\"k\", lw=1, ls=\"--\"\n",
    ")  # plot the shapefile given by the user as dashed line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "- As you can see now, also msk=2 values (red line) have been added along the coastal boundary\n",
    "- As you can see now, also msk=3 values (purple line) have been added along the lateral inland boundaries within the gdf_include shapefile\n",
    "- `reset_bounds=True` means that you start without initial boundary cells (of the specified type), if `reset_bounds=False` (default) you build on the existing boundary cells (if available)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Add river inflow points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive river from hydrography data based on a minimum river length (river_len)\n",
    "# and minimum upstream area (river_upa)\n",
    "\n",
    "sf.setup_river_inflow(\n",
    "    hydrography=\"merit_hydro\", river_len=1000, river_upa=50, keep_rivers_geom=True\n",
    ")\n",
    "\n",
    "# Make a plot of model\n",
    "# note the src points and derived river network\n",
    "fig, ax = sf.plot_basemap(variable=\"dep\", plot_bounds=False, bmap=\"sat\", zoomlevel=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> this is used when the making subgrid tables (step 8)\n",
    "\n",
    "# use the derived rivers to burn these into the model subgrid\n",
    "# note that the width and depth are arbitrary here\n",
    "\n",
    "gdf_riv = sf.geoms[\"rivers_inflow\"].copy()\n",
    "gdf_riv[\"rivwth\"] = [100, 50, 50]  # width [m]\n",
    "gdf_riv[\"rivdph\"] = 1.5  # depth [m]\n",
    "gdf_riv[\"manning\"] = 0.03  # manning coefficient [s.m-1/3]\n",
    "gdf_riv[[\"geometry\", \"rivwth\", \"rivdph\", \"manning\"]]\n",
    "\n",
    "# prepare the river dataset for the subgrid\n",
    "# instead of using the derived rivers, you could also use an aribitrary shapefile with centerlines\n",
    "# Other options include to add a river mask shapefile rather than a river width attribute\n",
    "# Note that the width is either specified on the river centerline or with a river mask\n",
    "# Also the river bed level (rivbed) can be specified instead of the river depth (rivdph).\n",
    "\n",
    "datasets_riv = [{\"centerlines\": gdf_riv}]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Add spatially varying roughness data:\n",
    "\n",
    "To ensure a correct lower roughness of the rivers in the domain, we 'burn in' the river with a lower manning roughness value. There is two different ways to do this:\n",
    "<ol>\n",
    "<li>Rasterize the manning value of gdf to the model grid and use this as a manning raster in datasets_rgh</li>\n",
    "<li>Provide a manning roughness for datasets_riv while burning in rivers into the subgrid</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. rasterize the manning value of gdf to the  model grid and use this as a manning raster\n",
    "# gdf_riv_buf = gdf_riv.assign(geometry=gdf_riv.buffer(gdf_riv['rivwth']/2))\n",
    "# da_manning = sf.grid.raster.rasterize(gdf_riv_buf, \"manning\", nodata=np.nan)\n",
    "\n",
    "# use the river manning raster in combination with vito land to derive the manning roughness file\n",
    "# NOTE that we can combine in-memory data with data from the data catalog\n",
    "# datasets_rgh = [{\"manning\": da_manning}, {\"lulc\": \"vito\"}]\n",
    "\n",
    "# uncomment to plot either the raster or the vector data:\n",
    "# da_manning.plot(vmin=0, x='xc', y='yc', cmap='viridis')\n",
    "# gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. provide the manning value to the datasets_riv and burn in the river with a lower manning value\n",
    "# a global manning value can be provided to the datasets_riv, or a manning value per river segment can be provided\n",
    "# NOTE when using this method, we don't need to provide the river manning values to the datasets_rgh\n",
    "datasets_rgh = [{\"lulc\": \"vito\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE This step can be skipped because we prepare a subgrid model,\n",
    "# the manning roughness is than included in the subgrid tables\n",
    "# For models without subgrid uncomment the following lines.\n",
    "\n",
    "# sf.setup_manning_roughness(\n",
    "#     datasets_rgh=datasets_rgh,\n",
    "#     manning_land=0.04,\n",
    "#     manning_sea=0.02,\n",
    "#     rgh_lev_land=0,  # the minimum elevation of the land\n",
    "# )\n",
    "# _ = sf.plot_basemap(variable=\"manning\", plot_bounds=False, bmap=\"sat\", zoomlevel=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Make subgrid derived tables:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subgrid derived tables are used to better capture the elevation and roughness of your domain, to either improve your results, or to allow you to run on a courser grid resolution (means faster simulation). For more info about subgrid tables, [click here](https://sfincs.readthedocs.io/en/latest/developments.html#recent-advancements-in-accuracy-subgrid-mode). \n",
    "\n",
    "You as user can specify multiple settings about how the subgrid derived tables should be made.\n",
    "\n",
    "Every single grid cell of the flux grid of the size inp.dx by inp.dy is defined into subgrid pixels (default nr_subgrid_pixels = 20).\n",
    "For every subgrid pixel the topobathy data is loaded, ideally this consists of high-resolution DEM datasets that you specify as user.\n",
    "\n",
    "In this example with dx=dy=50m, having nr_subgrid_pixels = 20 means we are loading data onto a 2.5 m subpixel grid\n",
    "However, the input data of Gebco and Merit_hydro is way coarser, therefore let's set the ratio to 5 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every single grid cell of the flux grid of the size inp.dx by inp.dy is defined into subgrid pixels (default is 20, nr_subgrid_pixels = 20).\n",
    "# For every subgrid pixel the topobathy data is loaded, ideally this consists also of high-resolution DEM datasets that you specify as user.\n",
    "\n",
    "sf.setup_subgrid(\n",
    "    datasets_dep=datasets_dep,\n",
    "    datasets_rgh=datasets_rgh,\n",
    "    datasets_riv=datasets_riv,\n",
    "    nr_subgrid_pixels=5,\n",
    "    write_dep_tif=True,\n",
    "    write_man_tif=False,\n",
    ")\n",
    "\n",
    "# NOTE: we turned on that the merged topobathy of the different (high-res) datasets is written to a geotiff\n",
    "\n",
    "# NOTE: if you have a very large domain with 100,000s to millions of cells, and very high-resolution datasets (e.g. 1 m), this step might take minutes to hours!!!\n",
    "#       But good news; when finished succesfully, you can very quickly run very accurate SFINCS simulations!\n",
    "#       The whole point of the subgrid functionality of SFINCS is that by derived subgrid tables based on high res elevation data,\n",
    "#       you either have more accurate results or run on a coarser grid resolution (= much faster) or both"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see what kind of subgrid-derived variables are created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to see the subgrid table variales\n",
    "# sf.subgrid\n",
    "\n",
    "# we can plot the 2D subgrid variables\n",
    "_ = sf.plot_basemap(\n",
    "    variable=\"subgrid.z_zmin\", plot_bounds=False, bmap=\"sat\", zoomlevel=12\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Add spatially varying infiltration data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent from subgrid files\n",
    "# curve number infiltration based on global CN dataset\n",
    "sf.setup_cn_infiltration(\"gcn250\", antecedent_moisture=\"avg\")\n",
    "\n",
    "# check all variables in the sf.grid dataset\n",
    "sf.grid.data_vars.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now we have made all basic SFINCS spatial layers to make the mskfile, infiltrationfile and subgridfiles, now we're going to add some forcing..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Add water level time-series as forcing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change period of model simulation time, specified in yyyymmdd HHMMSS --> simulation time here is 24 hours\n",
    "sf.setup_config(\n",
    "    **{\n",
    "        \"tref\": \"20100201 000000\",\n",
    "        \"tstart\": \"20100205 000000\",\n",
    "        \"tstop\": \"20100207 000000\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(sf.config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Specify water level input locations:**\n",
    "\n",
    "For more info about what the bndfile is, [click here](https://sfincs.readthedocs.io/en/latest/input_forcing.html#water-level-points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we specify at what x&y-locations we have measured/modelled input water level data in the bndfile of SFINCS:\n",
    "\n",
    "# x&y-locations in same coordinate reference system as the grid:\n",
    "x = [319526, 329195]\n",
    "y = [5041108, 5046243]\n",
    "\n",
    "# add to Geopandas dataframe as needed by HydroMT\n",
    "pnts = gpd.points_from_xy(x, y)\n",
    "index = [1, 2]  # NOTE that the index should start at one\n",
    "bnd = gpd.GeoDataFrame(index=index, geometry=pnts, crs=sf.crs)\n",
    "\n",
    "# show what has been created:\n",
    "display(bnd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Make up some time-series:**\n",
    "\n",
    "For more info about what the bzsfile is, [click here](https://sfincs.readthedocs.io/en/latest/input_forcing.html#water-level-time-serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we specify at what times we are providing water level input, and afterwards what the values are per input location:\n",
    "\n",
    "# In this case we will provide 3 values (periods=3) between the start (tstart=20100201 000000) and the end (tstop=20100201 120000) of the simulation:\n",
    "time = pd.date_range(\n",
    "    start=utils.parse_datetime(sf.config[\"tstart\"]),\n",
    "    end=utils.parse_datetime(sf.config[\"tstop\"]),\n",
    "    periods=3,\n",
    ")\n",
    "\n",
    "# and the actual water levels, in this case for input location 1 a water level rising from 0 to 2 meters and back to 0:\n",
    "bzs = [[0, 0.25], [0.75, 1.0], [0, 0.25]]\n",
    "\n",
    "bzspd = pd.DataFrame(index=time, columns=index, data=bzs)\n",
    "display(bzspd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually add it to the SFINCS model class:\n",
    "sf.setup_waterlevel_forcing(timeseries=bzspd, locations=bnd)\n",
    "\n",
    "# NOTE: the waterlevel forcing data is now stored in the sf.forcing dictionary\n",
    "sf.forcing.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Add an upstream discharge time-series as forcing:\n",
    "\n",
    "**a. specify discharge input locations: srcfile**\n",
    "\n",
    "For more info about what the srcfile is, [click here](https://sfincs.readthedocs.io/en/latest/input_forcing.html#discharge-points)\n",
    "\n",
    "**b. specify discharge time-series: disfile**\n",
    "\n",
    "For more info about what the disfile is, [click here](https://sfincs.readthedocs.io/en/latest/input_forcing.html#discharge-time-series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now use the previously created src discharge points (step 6)\n",
    "# Alternativly you can also create a new geodataframe with points, similar to the water level forcing points\n",
    "\n",
    "# make up some discharge data\n",
    "index = sf.forcing[\"dis\"].index\n",
    "dis = np.array([[2.0, 1.0], [5.0, 2.0], [2.0, 1.0]])\n",
    "dispd = pd.DataFrame(index=time, columns=index, data=dis)\n",
    "\n",
    "# now we call the function setup_discharge_forcing, which adds the discharge forcing to the src points\n",
    "sf.setup_discharge_forcing(timeseries=dispd)\n",
    "\n",
    "# # NOTE: the discharge forcing data is now stored in the sf.forcing dictionary\n",
    "sf.forcing.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to add other types of forcing, see the example notebook example_forcing.ipynb for other types.\n",
    "Or read more about this in the [SFINCS manual](https://sfincs.readthedocs.io/en/latest/input_forcing.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Add spatially varying rainfall data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly rainfall rates of ECMWF' ERA5 data for the specific area and period have been made available for this period in the artefact data\n",
    "sf.setup_precip_forcing_from_grid(precip=\"era5_hourly\", aggregate=False)\n",
    "\n",
    "# NOTE: the precipitation forcing data is now stored in the sf.forcing dictionary\n",
    "sf.forcing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot combined forcing time-series:\n",
    "_ = sf.plot_forcing(fn_out=\"forcing.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Add weirfile:\n",
    "In SFINCS, a weirfile is often used to explicity account for line-element features such as dikes, dunes or floodwalls. Read more about structures in the [SFINCS manual](https://sfincs.readthedocs.io/en/latest/input_structures.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example specify a 'line' style shapefile for the location of the weir to be added\n",
    "# NOTE: optional: dz argument - If provided, for weir structures the z value is calculated from the model elevation (dep) plus dz.\n",
    "sf.setup_structures(\n",
    "    structures=r\"data/compound_example_weirfile_input.geojson\",\n",
    "    stype=\"weir\",\n",
    "    dz=None,\n",
    ")\n",
    "\n",
    "# NOTE: the observation points are now stored in the sf.geoms dictionary\n",
    "sf.geoms.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Add observation points:\n",
    "\n",
    "For more info about what the obsfile is, [click here](https://sfincs.readthedocs.io/en/latest/input.html#observation-points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a point shapefile clicked by user:\n",
    "# NOTE: merge=True makes HydroMT merge the new observation points with already existing observation points (if present)\n",
    "sf.setup_observation_points(\n",
    "    locations=r\"data/compound_example_observation_points.geojson\", merge=True\n",
    ")\n",
    "\n",
    "# NOTE: the observation points are now stored in the sf.geoms dictionary\n",
    "sf.geoms.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Add observation lines:\n",
    "\n",
    "Observation lines (cross-sections) can be added to monitor discharges through cross-sections. For more info about what the crsfile is, [click here](https://sfincs.readthedocs.io/en/latest/input.html#cross-sections-for-discharge-output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a LineString GeoJson clicked by user:\n",
    "sf.setup_observation_lines(\n",
    "    locations=r\"data/compound_example_observation_lines.geojson\", merge=True\n",
    ")\n",
    "\n",
    "# NOTE: the observation lines are now stored in the sf.geoms dictionary\n",
    "sf.geoms.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Show model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use predefined plotting function 'plot_basemap' to show your full SFINCS model setup\n",
    "_ = sf.plot_basemap(fn_out=\"basemap.png\", bmap=\"sat\", zoomlevel=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Save all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write()  # write all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show created files in folder:\n",
    "dir_list = os.listdir(sf.root)\n",
    "print(dir_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your basemap and forcing figures are saved in the folder 'figs', GIS files (tiff & geojson) of your model setup in 'gis' and merged elevation and manning roughness on subgrid resolution in 'subgrid'.\n",
    "\n",
    "Now you have made a model, you can progress to the notebook: run_sfincs_model.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydromt-sfincs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ec3d1fca30a97858614ef59a1f03e9bb27fcbb0a81645b22c597c198da89e77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
