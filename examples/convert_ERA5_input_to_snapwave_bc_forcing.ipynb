{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://docs.xarray.dev/en/stable/user-guide/reshaping.html\n",
    "\n",
    "# array = xr.DataArray(\n",
    "#     np.random.randn(2, 2, 3), coords=[(\"time\", [0, 3600]),(\"lon\", [\"a\", \"b\"]), (\"lat\", [0, 1, 2])]\n",
    "# )\n",
    "\n",
    "# stacked = array.stack(stations=(\"lon\", \"lat\"))\n",
    "# stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import CRS\n",
    "\n",
    "epsg = 32617  # WGS 84 / UTM zone 17N\n",
    "crs = CRS.from_epsg(epsg)\n",
    "crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = setuplog(\"sfincs_outerbanks_hydromt\", log_level=10)\n",
    "from hydromt_sfincs import SfincsModel\n",
    "from hydromt_sfincs import utils\n",
    "\n",
    "ymlfile = r\"d:\\repos\\phd_waves\\paper_wave_driven_flooding\\02_modelling\\Outer_Banks_FloSup\\01_data_analysis\\dem\\new_flosup.yml\"\n",
    "sf_qt = SfincsModel(\n",
    "    data_libs=ymlfile, root=\"test_clip_ERA5\", mode=\"w+\"\n",
    ")  # , logger=logger)\n",
    "\n",
    "\n",
    "# for 400 m resolution SnapWave > refinement_level 1\n",
    "file_name = r\"d:\\repos\\phd_waves\\paper_wave_driven_flooding\\02_modelling\\Outer_Banks_FloSup\\02_model_setup\\shpfiles\\include_snapwave_offshore_plus_coast_refinelevel2.shp\"\n",
    "refine_gdf_lev1 = sf_qt.data_catalog.get_geodataframe(file_name, crs=4326)\n",
    "new_refine_gdf_lev1 = refine_gdf_lev1.to_crs(crs=crs)\n",
    "\n",
    "# 200m resolution of FLosup model > refinement_level 2\n",
    "file_name = r\"d:\\repos\\phd_waves\\paper_wave_driven_flooding\\02_modelling\\Outer_Banks_FloSup\\01_data_analysis\\from_flosup\\include_polygon_flosup_v5_UTM17N_tekal.pol\"\n",
    "\n",
    "refine_gdf_lev2 = utils.polygon2gdf(feats=utils.read_geoms(fn=file_name), crs=crs)\n",
    "\n",
    "gdf_refinement = gpd.GeoDataFrame(\n",
    "    {\n",
    "        \"refinement_level\": [\n",
    "            1,\n",
    "            2,\n",
    "        ]\n",
    "    },\n",
    "    # {\"refinement_level\": [5,]},\n",
    "    geometry=[\n",
    "        new_refine_gdf_lev1.unary_union,\n",
    "        refine_gdf_lev2.unary_union,\n",
    "    ],\n",
    "    crs=crs,\n",
    ")\n",
    "\n",
    "gdf_refinement\n",
    "output_file = r\"d:\\repos\\phd_waves\\paper_wave_driven_flooding\\02_modelling\\Outer_Banks_FloSup\\02_model_setup\\shpfiles\\include_polygon_flosup_v5_UTM17N_tekal.geojson\"\n",
    "# gdf_refinement.to_file(output_file, driver='GeoJSON')\n",
    "\n",
    "sf_qt.setup_grid(\n",
    "    x0=656551,\n",
    "    y0=3470589,\n",
    "    dx=800.0,\n",
    "    dy=800.0,\n",
    "    nmax=647,\n",
    "    mmax=954,\n",
    "    rotation=40.0,\n",
    "    epsg=epsg,  # WGS 84 / UTM zone 17N\n",
    "    refinement_polygons=gdf_refinement,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"p:\\archivedprojects\\11206515-flosup2021\\01_data\\ERA5\\ERA5_waves2018.nc\"\n",
    "\n",
    "era5 = xr.open_dataset(filename)\n",
    "era5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try cliping ERA5 data to domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5new = era5.copy()\n",
    "# we need: \"hs\", \"tp\", \"wd\", \"ds\"\n",
    "era5new = era5new.rename({\"swh\": \"hs\"})\n",
    "era5new = era5new.rename({\"mwp\": \"tp\"})\n",
    "era5new = era5new.rename({\"mwd\": \"wd\"})\n",
    "\n",
    "# add directional spreading\n",
    "era5new = era5new.assign(ds=30.0 * xr.ones_like(era5new[\"hs\"]))\n",
    "\n",
    "#  rename\n",
    "era5new = era5new.set_coords([\"longitude\", \"latitude\"])\n",
    "# ds = ds.rename_vars({\"point_hm0\":\"hs\", \"point_tp\":\"tp\", \"point_wavdir\":\"wd\", \"point_dirspr\":\"ds\"})\n",
    "era5new = era5new.rename(\n",
    "    {\"longitude\": \"lon\", \"latitude\": \"lat\"}\n",
    ")  # , \"stations\": \"index\"})\n",
    "era5new = era5new.set_coords([\"lon\", \"lat\"])\n",
    "\n",
    "# convert coordinates\n",
    "tmp = era5new.coords[\n",
    "    \"lon\"\n",
    "].values  # = era5new.coords['lon'].values - 360 #convert [0-360] to [-180,180]\n",
    "tmp2 = tmp - 360\n",
    "era5new.coords[\"lon\"] = tmp2\n",
    "\n",
    "# Fill NaN values with zero\n",
    "era5new = era5new.fillna(0)\n",
    "era5new.attrs[\"crs\"] = \"EPSG:4326\"  # Example CRS: WGS84\n",
    "\n",
    "era5new\n",
    "# era5new.to_netcdf(r'd:\\repos\\phd_waves\\paper_wave_driven_flooding\\02_modelling\\Outer_Banks_FloSup\\01_data_analysis\\ERA5\\ERA5_waves2018_rename_added_ds.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5new.coords[\"lon\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = era5new.coords[\"lon\"].values\n",
    "lat = era5new.coords[\"lat\"].values\n",
    "\n",
    "[lon2d, lat2d] = np.meshgrid(lon, lat)\n",
    "\n",
    "lon2dflat = lon2d.flat\n",
    "lat2dflat = lat2d.flat\n",
    "\n",
    "# Create a GeoDataFrame from the coordinates\n",
    "gdf = gpd.GeoDataFrame(geometry=gpd.points_from_xy(lon2dflat, lat2dflat), crs=4326)\n",
    "gdf\n",
    "# # # Create a GeoDataFrame\n",
    "gdf.plot()\n",
    "output_file = r\"d:\\repos\\phd_waves\\paper_wave_driven_flooding\\02_modelling\\Outer_Banks_FloSup\\02_model_setup\\shpfiles\\ERA5_points.geojson\"\n",
    "# gdf.to_file(output_file, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = r\"d:\\repos\\phd_waves\\paper_wave_driven_flooding\\02_modelling\\Outer_Banks_FloSup\\01_data_analysis\\ERA5\\select_era5_points.shp\"\n",
    "include_era5 = sf_qt.data_catalog.get_geodataframe(file_name, crs=4326)\n",
    "include_era5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if points are inside the polygon\n",
    "gdf[\"inside_polygon\"] = gdf.within(include_era5.unary_union)\n",
    "\n",
    "# print(gdf['inside_polygon'] == True)\n",
    "# Spatial join to check which points are within the polygon\n",
    "points_within_polygon = gpd.sjoin(gdf, include_era5, how=\"inner\", op=\"within\")\n",
    "points_within_polygon\n",
    "\n",
    "# index = points_within_polygon.index\n",
    "# index\n",
    "xpoint = points_within_polygon.geometry.centroid.x\n",
    "ypoint = points_within_polygon.geometry.centroid.y\n",
    "\n",
    "# Convert the geometry column of the GeoDataFrame to a list\n",
    "geometry_list = points_within_polygon[\"geometry\"].tolist()\n",
    "geometry_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "gdf.plot(ax=ax)\n",
    "include_era5.plot(ax=ax, color=\"r\", ls=\"--\")  # , facealpha=0.5)\n",
    "ax.scatter(xpoint, ypoint, color=\"y\")\n",
    "\n",
    "ax.set_xlim(-82, -74)\n",
    "ax.set_ylim(31, 38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask to filter out the specific points\n",
    "mask = xr.DataArray(\n",
    "    False, dims=(\"lon\", \"lat\"), coords={\"lon\": era5new[\"lon\"], \"lat\": era5new[\"lat\"]}\n",
    ")\n",
    "\n",
    "for point in geometry_list:\n",
    "    x_coordinate = point.x\n",
    "    y_coordinate = point.y\n",
    "\n",
    "    # mask.loc[x_coordinate,y_coordinate] = True\n",
    "    mask.loc[{\"lon\": x_coordinate, \"lat\": y_coordinate}] = True\n",
    "\n",
    "# Apply the mask to extract the specific points\n",
    "selected_points = era5new.where(mask, drop=False)\n",
    "\n",
    "print(selected_points)\n",
    "# print(mask)\n",
    "mask.plot(x=\"lon\", y=\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_points[\"hs\"][0, :, :].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack 2D grid into 1D 'stations'\n",
    "stacked = selected_points.stack(stations=(\"lon\", \"lat\"))\n",
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove filtered out stations\n",
    "ds_cleaned = stacked.dropna(dim=\"stations\", how=\"all\")\n",
    "ds_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cleaned[\"hs\"][:, 1].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_index()\n",
    "ds_cleaned.reset_index(\"stations\")\n",
    "\n",
    "ds_reset = ds_cleaned.reset_index(\"stations\")\n",
    "ds_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_spatial_dims\n",
    "\n",
    "ds_reset = ds_reset.rename({\"lon\": \"x\"})\n",
    "ds_reset = ds_reset.rename({\"lat\": \"y\"})\n",
    "ds_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save:\n",
    "file_name = r\"d:\\repos\\phd_waves\\paper_wave_driven_flooding\\02_modelling\\Outer_Banks_FloSup\\01_data_analysis\\ERA5\\ERA5_waves2018_rename_added_ds_cleaned.nc\"\n",
    "ds_reset.to_netcdf(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually write data now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_qt.config[\"tref\"] = \"20180904 000000\"\n",
    "sf_qt.config[\"tstart\"] = \"20180910 152325\"\n",
    "sf_qt.config[\"tstop\"] = \"20180928 190000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_reprojected = ds_reset.rio.reproject(crs)\n",
    "# ds_reset.raster.to_crs(self.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = ds_reset.transpose(..., ds_reset.vector.index_dim).to_dataframe()\n",
    "gdf_locs = ds_reset.vector.to_gdf()\n",
    "gdf_locs2 = gdf_locs.copy()\n",
    "gdf_locs2 = gdf_locs2.to_crs(crs)\n",
    "gdf_locs2\n",
    "# crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_qt.setup_wave_forcing(ds_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_qt.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sf_qt.setup_wave_forcing(geodataset = 'era5_waves_2018_rename')\n",
    "\n",
    "# data_era5 = r'd:\\repos\\phd_waves\\paper_wave_driven_flooding\\02_modelling\\Outer_Banks_FloSup\\01_data_analysis\\ERA5\\ERA5_waves2018_rename_added_ds.nc'\n",
    "# ds =  xr.open_mfdataset(data_era5)\n",
    "\n",
    "# ds = ds.set_coords([\"longitude\", \"latitude\"])\n",
    "# # ds = ds.rename_vars({\"point_hm0\":\"hs\", \"point_tp\":\"tp\", \"point_wavdir\":\"wd\", \"point_dirspr\":\"ds\"})\n",
    "# ds = ds.rename({\"longitude\": \"lon\", \"latitude\" : \"lat\"})#, \"stations\": \"index\"})\n",
    "# ds = ds.set_coords([\"lon\", \"lat\"])\n",
    "# #ds = ds.set_index(stations = [\"station_x\", \"station_y\"], append = True )\n",
    "\n",
    "# lon = era5.coords['longitude'].values - 360 #convert [0-360] to [-180,180]\n",
    "# lat = era5.coords['latitude'].values\n",
    "\n",
    "# [lon2d, lat2d] = np.meshgrid(lon,lat)\n",
    "\n",
    "# lon2dflat = lon2d.flat\n",
    "# lat2dflat = lat2d.flat\n",
    "\n",
    "# ds\n",
    "# #TODO: try as flat 1D arrays > first selected within range? lat/lon/time\n",
    "# # ds\n",
    "# # sf_qt.setup_wave_forcing(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fn = r'd:\\repos\\phd_waves\\paper_wave_driven_flooding\\02_modelling\\LaJola\\01_data_analysis\\ndbc_station46254_2015_nearshore_clean_smooth.nc'\n",
    "# fn = r'p:\\archivedprojects\\11206515-flosup2021\\01_data\\ERA5\\ERA5_waves2018.nc'\n",
    "\n",
    "# ndbc_deep = xr.open_dataset(fn)\n",
    "\n",
    "# ndbc_deep\n",
    "\n",
    "# # x&y-locations:\n",
    "# x = ndbc_deep.station_x\n",
    "# y = ndbc_deep.station_y\n",
    "\n",
    "# # add to Geopandas dataframe as needed by HydroMT\n",
    "# pnts = gpd.points_from_xy(x, y)\n",
    "# index = [1]  # NOTE that the index should start at one\n",
    "# bnd = gpd.GeoDataFrame(index=index, geometry=pnts, crs=4326)\n",
    "# bnd\n",
    "\n",
    "\n",
    "# # Wanted values:\n",
    "# hs = ndbc_deep.hs #[[5.0], [5.0]]\n",
    "# tp = ndbc_deep.tp #[[10.0], [10.0]]\n",
    "# dir = ndbc_deep.mwd #[[290.0], [290.0]]\n",
    "\n",
    "# # Assumption wave spreading\n",
    "# s = 20.0\n",
    "# sigma = np.sqrt(2 / (s + 1)) / np.pi * 180.0 #s  =    20 > to degress\n",
    "\n",
    "# # ds = hs.copy()\n",
    "# # ds = ds.where(ds > 0, sigma)\n",
    "# ds = sigma * np.ones_like(hs)\n",
    "# # ds.values = sigma\n",
    "\n",
    "# ds\n",
    "# # ds['hs'].values = sigma\n",
    "# # # ds = sigma * np.ones_like(hs) #[[sigma], [sigma]]\n",
    "# time = ndbc_deep.time# [0, 99999]\n",
    "\n",
    "# df_hs = pd.DataFrame(index= time, data = hs)\n",
    "# df_tp = pd.DataFrame(index= time, data = tp)\n",
    "# df_dir = pd.DataFrame(index= time, data = dir)\n",
    "# df_ds = pd.DataFrame(index= time, data = ds)\n",
    "\n",
    "# list_df = [df_hs, df_tp, df_dir, df_ds]\n",
    "\n",
    "# list_df\n",
    "\n",
    "# sf_qt.setup_wave_forcing(timeseries = list_df, locations= bnd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydromt-sfincs-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
